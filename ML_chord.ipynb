{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project : chord embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "When loading the key dataset, we can choose whether to drop one-word sentences.  \n",
    "When loading the chord dataset, we can choose whether to keep sections in major or minor key, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_chord_data, load_key_data, all_composers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional parameter for load_key_data: drop_one_worders = True/False\n",
    "bach_key = load_key_data(all_composers)\n",
    "\n",
    "# Optional parameter for load_chord_data: key_mode = 'both'/'major'/'minor'\n",
    "bach_chord_both = load_chord_data(all_composers, key_mode='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore words with a lower frequency frequency than this\n",
    "min_count = 10\n",
    "# Size of the embedding space\n",
    "size = 20 \n",
    "# Neighborhood of the focus word to study\n",
    "window = 2\n",
    "# 0 for CBOW, 1 for skip-gram\n",
    "sg = 0 \n",
    "\n",
    "# The first argument has to be a list of lists of words\n",
    "model_bach_both = Word2Vec(bach_chord_both, min_count=min_count, size=size, window=window, sg=sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality and visualise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dimensionality: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from reduce_dim import reduce_dim_keyed_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "tsne = TSNE(n_components=2)\n",
    "wv_red = reduce_dim_keyed_vec(model_bach_both.wv, pca.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual import visual_reduced_chord_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_reduced_chord_vectors(wv_red, dimred_method='PCA', plot_title='W2V. Bach: both keys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bach_both.wv.similarity('MINOR;I:MIN', 'MINOR;V:DIM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bach_both.wv.most_similar('MINOR;I:MIN', topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bach_both.wv.most_similar('MAJOR;I:MIN', topn = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_in_one(composers, key_mode = 'both', min_count = 10, size = 20, window=2, sg=0,\n",
    "               dimred_method = 'PCA', plot_title = 'W2V. Bach: both keys', topn = 4, draw_grath=True, \n",
    "               print_similarities=True ):\n",
    "    \n",
    "    # Optional parameter for load_chord_data: key_mode = 'both'/'major'/'minor'\n",
    "    chords = load_chord_data(composers, key_mode)\n",
    "\n",
    "    # The first argument has to be a list of lists of words\n",
    "    model = Word2Vec(chords, min_count=min_count, size=size, window=window, sg=sg)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    tsne = TSNE(n_components=2)\n",
    "    wv_red = None \n",
    "    if dimred_method=='PCA':\n",
    "        wv_red = reduce_dim_keyed_vec(model.wv, pca.fit_transform)\n",
    "    elif dimred_method=='TSNE':\n",
    "        wv_red = reduce_dim_keyed_vec(model.wv, tsne.fit_transform)\n",
    "    \n",
    "    if draw_grath:\n",
    "        visual_reduced_chord_vectors(wv_red, dimred_method = dimred_method, plot_title=plot_title)\n",
    "    \n",
    "    if print_similarities:\n",
    "        sorted_chords=list(model.wv.vocab.keys())\n",
    "        sorted_chords.sort()\n",
    "        for chord in sorted_chords:\n",
    "            similar=':'\n",
    "            for neighbour, similarity in model.wv.most_similar(chord, topn=topn):\n",
    "                similar +=f' ({neighbour}, {similarity:.3f}),'\n",
    "            print(chord + similar)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
